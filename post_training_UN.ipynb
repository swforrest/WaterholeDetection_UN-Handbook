{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Testing the trained network and output generation\"\n",
    "author:\n",
    "  - name: Adriano Fossati\n",
    "    url: https://github.com/AdrianoGuidoF\n",
    "    orcid: 0009-0008-9751-4599\n",
    "    affiliation: Queensland University of Technology\n",
    "    email: \"afossati.academia@gmail.com\"\n",
    "date: today\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        number_sections: true\n",
    "        code-fold: true # to hide the code by default, but have the option to show it\n",
    "        # code-fold: show # to show the code by default, but have the option to hide it\n",
    "        code-tools: true\n",
    "        code-summary: \"Show the code\"\n",
    "        code-overflow: scroll\n",
    "        # embed-resources: true\n",
    "        css: styles.css\n",
    "# bibliography: references.bib\n",
    "abstract: |\n",
    "  Download environmental layers using Google Earth Engine (GEE).  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to proceed with the following steps once the yolo model has been trained. Will run manually here sequences of the classify.py and testing.py scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the runing of this section can be done by calling modes that run pipelines out of Charlie's code. Let's see how much of those automatisations can be used here. \n",
    "Here is his comment from the testing.py file:\n",
    "\n",
    "Utility functions for training/validation pipeline.  \n",
    "Includes: \n",
    "\n",
    "    - prepare: Prepare the images for segmentation\n",
    "    - segment: Segment the images\n",
    "    - run_detection: Run the YoloV5 detection\n",
    "    - backwards_annotation: Generate labelme style annotations from the classifications\n",
    "    - compare_detections_to_ground_truth: Match up labels and detections, compare them, and save the results\n",
    "    - confusion_matrix: Summarize the results of the comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load first all the configs and required packs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fossatia\\AppData\\Local\\miniconda3\\envs\\Boats\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5  v7.0-394-g86fd1ab2 Python-3.10.16 torch-1.12.1+cu113 CUDA:0 (GeForce GTX 1080, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "import yaml \n",
    "import argparse\n",
    "import os.path as path\n",
    "import scipy.cluster\n",
    "import scipy.spatial\n",
    "import json\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import stat\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "from counting_boats.boat_utils.config import cfg\n",
    "from counting_boats.boat_utils import image_cutting_support as ics\n",
    "from counting_boats.boat_utils import heatmap as hm\n",
    "\n",
    "import counting_boats.boat_utils.classifier\n",
    "# cluster, process_clusters, read_classifications, pixel2latlong\n",
    "\n",
    "# Add the project root to sys.path (adjust as needed)\n",
    "sys.path.append(os.path.abspath(\"counting_waterholes\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can select manually which function we want to run. \n",
    "First, from the testing aoi tif file, we need to prepare the padded png image using the testing.prepare():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preparation:\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "\n",
    "counting_boats.boat_utils.testing.prepare(\"counting_waterholes/testing\", \"config_test_GPU.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I need to use the created png to label it with labelme. This will allow us to compare my annotation to the detection of the trained model i.e. test the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the manual annotation is done, we can apply the segmentation used from the testing.segment():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping Image: D:/Waterholes_project/counting_waterholes/testing\\./pngs\\20240204_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [05:33<00:00, 47.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 728 images\n",
      "Empty 0 images\n",
      "Cropping Image: D:/Waterholes_project/counting_waterholes/testing\\./pngs\\20240324_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [08:10<00:00, 32.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 1676 images\n",
      "Empty 0 images\n",
      "Cropping Image: D:/Waterholes_project/counting_waterholes/testing\\./pngs\\20240415_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [11:48<00:00, 22.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 790 images\n",
      "Empty 0 images\n",
      "Segregating by day...\n",
      "01_01_2024\n",
      "04_02_2024\n",
      "24_03_2024\n",
      "15_04_2024\n",
      "Segregating by image...\n",
      "Segregating by image...\n",
      "Segregating by image...\n",
      "Segregating by image...\n",
      "Segregating by day...\n",
      "01_01_2024\n",
      "04_02_2024\n",
      "24_03_2024\n",
      "15_04_2024\n",
      "Segregating by image...\n",
      "Segregating by image...\n",
      "Segregating by image...\n",
      "Segregating by image...\n"
     ]
    }
   ],
   "source": [
    "#run segmentation without spliting 80% of the images for validation!\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.segment(r\"D:/Waterholes_project/counting_waterholes/testing\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those segmented labelled images, we can run the detection of waterholes using the trained model, and compare my label with the detection of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging section to recognise and work well with the GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to user: Need to update the torchvision to match the cuda (GPU) version. using the 'nvidia-smi' command, you get the cuda version (my case: 11) so I need to get a version of torch and torchaudio with to 11.xx. Need to 'pip uninstall torch torchvision', and then install the correct version, in my case: 'pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113'  \n",
    "Other version to be found on this website: https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing.segment function and run_detection work to use the segmented images folders grouped per date. left as it is for now but just something to bear in mind!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check of the GPU found or not?\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run detection on my testing \n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.run_detection(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy of the order command that is run run to yolo cmd  by the function run_detectionpage. Just in order to debug and be informative. Do not run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python C:/Users/fossatia/Documents/Waterholes_project/yolov5/detect.py --imgsz 416 --save-txt --save-conf --weights C:/Users/fossatia/Documents/Waterholes_project/yolov5/runs/train/exp3/weights/best.pt --source D:\\\\Waterholes_project\\\\counting_waterholes\\\\testing\\\\segmented_images\\\\04_02_2024\\\\20240204_mimal_test --device cuda:0 --nosave --conf-thres 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the detection output of the model on my testing images to produce labelme style annotation using the backwards_annotation():  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the annotation of the images using the detection of the model:\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.backwards_annotation_AF(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then finally, compare the detected WH with my labeled WH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label directory D:/Waterholes_project/counting_waterholes/testing_v3\\./labels\\05_02_2025\\050225_NT does not exist, skipping image...\n",
      "raw_images folder D:/Waterholes_project/counting_waterholes/testing_v3\\./raw_images\n",
      "Could not parse date from 050225_NT.csv\n"
     ]
    }
   ],
   "source": [
    "#comparison of my labels with the detected WH:\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.compare_detections_to_ground_truth(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the confusion matrix which summarises the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the confusion matrix\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.confusion_matrix_AF(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to process a single images by comparing the detections and labels for a single image, used in a function but not usefull by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create the confusion matrix\n",
    "# import counting_boats.boat_utils.testing\n",
    "\n",
    "# counting_boats.boat_utils.testing.process_image_AF(r\"D:\\Waterholes_project\\counting_waterholes\\testing_v3\\classifications\", r\"D:/Waterholes_project/counting_waterholes/testing_v3/labels\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the counts one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison labelled vs detected WH:\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.waterholes_count_compare(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the waterholes on the images. To do that, I need first to stich the training images together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max x: 92, Max y: 60\n",
      "Saved stitched image to D:\\Waterholes_project\\counting_waterholes\\testing_v3\\stitching\\stitched.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import counting_boats.boat_utils.stitch_PNGs\n",
    "\n",
    "counting_boats.boat_utils.stitch_PNGs.stitch(r\"D:\\Waterholes_project\\counting_waterholes\\testing_v3\\stitching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to plot the waterholes, but the function is made for boats so I need to modify it to work on WH. WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot WH using that stiched image:\n",
    "import counting_boats.boat_utils.testing\n",
    "\n",
    "counting_boats.boat_utils.testing.plot_waterholes(r\"D:/Waterholes_project/counting_waterholes/testing_v3\", \"config_test_Drive.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Boats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
