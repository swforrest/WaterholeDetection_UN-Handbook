[
  {
    "objectID": "S2_download_GEE.html",
    "href": "S2_download_GEE.html",
    "title": "GEE Environmental Covariates",
    "section": "",
    "text": "Show the code\nimport os\nimport ee\nimport geemap\nimport json\nimport requests\n\nfrom PIL import Image\n\n\n\n\nShow the code\n# Initialize Earth Engine\ntry:\n    ee.Initialize()\n    print(\"Earth Engine already initialized\")\nexcept Exception as e:\n    ee.Authenticate()\n    ee.Initialize()\n    print(\"Earth Engine initialized\")\n\n\n\n            \n            \n\n\nEarth Engine already initialized\n\n\n\n\n\n\nShow the code\nMap = geemap.Map(lite_mode=True)\nMap.add_basemap(\"SATELLITE\")\nMap\n\n\n\n            \n            \n\n\n\n\n\n\n\n\n\n\nShow the code\n# Option 1: Read JSON from file\ndef load_aoi_from_file(json_file_path):\n    with open(json_file_path, 'r') as f:\n        geojson = json.load(f)\n    \n    # Create an ee.Geometry from the GeoJSON\n    return ee.Geometry(geojson)\n\n\n\n            \n            \n\n\n\n\nShow the code\n# Option 1: Define AOI as a geometry\n# aoi = ee.Geometry.Rectangle([-122.5, 37.5, -122.0, 38.0])  # San Francisco area\n\naoi_name = 'example'\naoi = load_aoi_from_file(fr'C:\\Users\\for329\\OneDrive - Queensland University of Technology\\FirstByte Waterholes WD\\counting_waterholes\\data\\polygons\\{aoi_name}.geojson')\n\n# Show the AOI on map\nMap.addLayer(aoi, {}, 'Area of Interest')\n# Center the map on the AOI and zoom to it\nMap.centerObject(aoi, zoom=10)  # Adjust zoom level (1-20) as needed\nMap  # Display the map with the AOI"
  },
  {
    "objectID": "S2_download_GEE.html#plot-the-basemap",
    "href": "S2_download_GEE.html#plot-the-basemap",
    "title": "GEE Environmental Covariates",
    "section": "",
    "text": "Show the code\nMap = geemap.Map(lite_mode=True)\nMap.add_basemap(\"SATELLITE\")\nMap"
  },
  {
    "objectID": "S2_download_GEE.html#import-aoi",
    "href": "S2_download_GEE.html#import-aoi",
    "title": "GEE Environmental Covariates",
    "section": "",
    "text": "Show the code\n# Option 1: Read JSON from file\ndef load_aoi_from_file(json_file_path):\n    with open(json_file_path, 'r') as f:\n        geojson = json.load(f)\n    \n    # Create an ee.Geometry from the GeoJSON\n    return ee.Geometry(geojson)\n\n\n\n            \n            \n\n\n\n\nShow the code\n# Option 1: Define AOI as a geometry\n# aoi = ee.Geometry.Rectangle([-122.5, 37.5, -122.0, 38.0])  # San Francisco area\n\naoi_name = 'example'\naoi = load_aoi_from_file(fr'C:\\Users\\for329\\OneDrive - Queensland University of Technology\\FirstByte Waterholes WD\\counting_waterholes\\data\\polygons\\{aoi_name}.geojson')\n\n# Show the AOI on map\nMap.addLayer(aoi, {}, 'Area of Interest')\n# Center the map on the AOI and zoom to it\nMap.centerObject(aoi, zoom=10)  # Adjust zoom level (1-20) as needed\nMap  # Display the map with the AOI"
  },
  {
    "objectID": "S2_download_GEE.html#get-monthly-composites-of-sentinel-2",
    "href": "S2_download_GEE.html#get-monthly-composites-of-sentinel-2",
    "title": "GEE Environmental Covariates",
    "section": "Get Monthly Composites of Sentinel-2",
    "text": "Get Monthly Composites of Sentinel-2\n\n\nShow the code\ndef get_monthly_composites(start_date, end_date, aoi):\n    \"\"\"Generate monthly S2 composites for the given date range and AOI.\"\"\"\n    # Convert date strings to ee.Date objects\n    start = ee.Date(start_date)\n    end = ee.Date(end_date)\n    \n    # Get number of months\n    months = end.difference(start, 'month').round().int()\n\n    # First, check if we have any S2 data for this month (without filtering)\n    raw_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n        .filterBounds(aoi) \\\n        .filterDate(start_date, end_date)\n    \n    raw_count = raw_collection.size().getInfo()\n    print(f\"  Found {raw_count} raw S2 images for {start_date} to {end_date}\")\n    \n    # Function to get image for a specific month\n    def get_monthly_image(month_index):\n        # Calculate current month start and end\n        current_month_start = start.advance(month_index, 'month')\n        current_month_end = current_month_start.advance(1, 'month')\n        \n        # Format dates for naming\n        date_format = current_month_start.format('YYYY-MM')\n        \n        # Get S2 collection for this month\n        s2_collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n            .filterBounds(aoi) \\\n            .filterDate(current_month_start, current_month_end) \\\n            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 90)) \\\n            .map(maskS2clouds_SCL)\n        \n        # # Check if we have any images left after cloud filtering\n        # filtered_count = s2_collection.size().getInfo()\n        # print(f\"  After cloud filtering: {filtered_count} images remain\")\n        \n        # Create a median composite and clip to AOI\n        composite = s2_collection.median().clip(aoi)\n        \n        # Select RGB bands and scale for visualization\n        # Bands: B2 (blue), B3 (green), B4 (red)\n        # These get re-ordered to RGB by the image_cutting_support.create_padded_png_S2 function\n        rgb = composite.select(['B2', 'B3', 'B4'])\n        \n        return rgb.set({\n            'system:index': date_format,\n            'system:time_start': current_month_start.millis()\n        })\n    \n    # Create a list of months\n    month_indices = ee.List.sequence(0, months)\n    \n    # Map the function over the months\n    composites = ee.ImageCollection.fromImages(\n        month_indices.map(get_monthly_image)\n    )\n    \n    return composites"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WaterholeDetection_UN-Handbook",
    "section": "",
    "text": "This project aims to detect and assess the locations of waterholes in Northern Australia using satellite imagery and machine learning. The primary focus is on identifying waterholes susceptible to damage from invasive herbivores such as water buffalo, feral cattle, and pigs."
  },
  {
    "objectID": "index.html#project-background",
    "href": "index.html#project-background",
    "title": "WaterholeDetection_UN-Handbook",
    "section": "Project Background",
    "text": "Project Background\nAdapted from an existing boat detection pipeline, this project leverages satellite image analysis and YOLOv5 object detection to map and evaluate waterholes in the Arnhem Land and Cape York regions. While originally based on the CountingBoats repository, our workflow has been modified to use Jupyter notebooks for increased clarity and control."
  },
  {
    "objectID": "index.html#how",
    "href": "index.html#how",
    "title": "WaterholeDetection_UN-Handbook",
    "section": "How",
    "text": "How\nThe project follows a comprehensive pipeline:\n\nImage Acquisition:\n\n\nUse Planet satellite imagery service to order recent images of the target area\nAutomatically download imagery for the specified region and date range\n\n\nPre-processing:\n\n\nPrepare satellite images for neural network detection\nConvert and normalize imagery to suitable format\n\n\nDetection:\n\n\nUtilize a pre-trained YOLOv5 model to detect and classify waterholes\nGenerate comprehensive output with waterhole locations, classifications, and coordinates\n\n\nAnalysis:\n\n\nCollate detection results\nOutput CSV with detailed waterhole information"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Getting Started",
    "section": "",
    "text": "Installation\nClone this repository. Will allow you to run all the notebooks and follow the instructions bellow.\n\nYolov5\nClone YoloV5. This is used for the Neural Network detections.\n\n\nPython Dependencies\nItâ€™s recommended to install a conda-based package manager such as Miniconda.\nRunning the following will then install all required dependencies (run only once to set the environment up):\nconda env create --file env.yaml\n\n\n\nSetup\nTo start working on this project, activate the environment with:\nconda activate Boats\n\nConfigurations\nModify configuration files to match your specific environment and research requirements: - config_train_Drive.yaml: Training configuration - config_test_Drive.yaml: Testing configuration\n- config_deploy_Drive.yaml: Deployment configuration\n\n\n\nRunning\nAs mentionned, the whole pipeline flow designed by Charlie Turner for the boat detection, is not used here. You will need to run specific blocks of code in the respective jupyter notebooks of each stage of our workflow.\n\nImages dowload\nUsing the notebook planet_download.ipynb, you will: - Define Area of Interest (AOI) - Specify output directory and date range - Download and extract satellite imagery\n\n\nPrepare for training\nUsing the notebook from_tif_to_trainable_AF.ipynb, you will: - Convert .tif files to training-ready format - Prepare data for neural network training\n\n\nTraining\nEither simply run the last code block from from_tif_to_trainable_AF.ipynb function train() or copy paste the function output in the yolov5 folder command prompt.\n\n\nTesting\nUsing the notebook post_training.ipynb, the notebook will guide you along the main steps to test the model you just trained. Those steps are:\n- Prepare images for segmentation - Run model detection - Generate annotations - Compare detections to ground truth - Create confusion matrix - Visualize waterhole detections\n\n\nDeployment\nOriginally the repository had a whole section about the classifying process, which included many functions dependent on the classes of the detection. The adaptation of this existing code to waterhole detection, has proven to be more difficult and time consumming than anticipated. As a result, The deployment section of the repository is still under development and requires further debugging. Some functions are created but need refinement for smooth operation.\n\n\nVisualisation\nThere are some visualisation notebooks in the visualisation folder. These can be run to perform some visualisations of the data. The plot_output script is also a useful tool for visualising the output of the detection model on individual images.\nAll thos functions and modules were developped for the visualisation of Boats and was not adapted to waterholes by lack of time.\n\n\n\nAcknowledgements\nWe acknowledge Charlie Turner and other collaborators for their work on the Boat detection repository, largely foundamental to the existance of this repository."
  }
]