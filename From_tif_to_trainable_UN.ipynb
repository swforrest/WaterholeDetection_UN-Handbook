{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Training preparation steps\"\n",
    "author:\n",
    "  - name: Adriano Fossati\n",
    "    url: https://github.com/AdrianoGuidoF\n",
    "    orcid: 0009-0008-9751-4599\n",
    "    affiliation: Queensland University of Technology\n",
    "    email: \"afossati.academia@gmail.com\"\n",
    "date: today\n",
    "format:\n",
    "    html:\n",
    "        toc: true\n",
    "        number_sections: true\n",
    "        code-fold: true # to hide the code by default, but have the option to show it\n",
    "        # code-fold: show # to show the code by default, but have the option to hide it\n",
    "        code-tools: true\n",
    "        code-summary: \"Show the code\"\n",
    "        code-overflow: scroll\n",
    "        # embed-resources: true\n",
    "        css: styles.css\n",
    "# bibliography: references.bib\n",
    "abstract: |\n",
    "  This script handles the image zip file once they have been downloaded using the planet_download.ipynb Jupyter notebook up to a product allowing us to train a model.  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will apply the extraction from the zip file of downloaded images from Planet; Prepare the images creating the PNG images from the tif file allowing for the manual annotation; and will segment the images describe them for check, and cull them to suit the model requirements, and finally apply the model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First. we define the parth of the project, and refer the python code to the correct python scripts containing the functions that are automatically called when running dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fossatia\\AppData\\Local\\miniconda3\\envs\\Boats\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5  v7.0-394-g86fd1ab2 Python-3.10.16 torch-1.12.1+cu113 CUDA:0 (GeForce GTX 1080, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Add the project root to sys.path (adjust as needed)\n",
    "sys.path.append(os.path.abspath(\"counting_waterholes\"))\n",
    "\n",
    "\n",
    "import counting_boats.boat_utils.planet_utils as planet_utils\n",
    "import counting_boats.boat_utils.testing as testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the file called \"composite.tif\" obtained from the planet order and downloaded into the zip file in our \"raw_images\" folder. It will render a tif file and will rename it with the date_aoi.tif outside the zip file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import counting_boats.boat_utils.planet_utils\n",
    "\n",
    "# Define the path to your zip file\n",
    "zip_path = \"images/raw_images\" \n",
    "#AFUN: should this path be training/raw_images? \n",
    "#If so, need to be careful where we download the image zip file. Might need to adaot this. \n",
    "\n",
    "# Run extraction\n",
    "counting_boats.boat_utils.planet_utils.extract_zip(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now transform the raw tif image into a usable png for future steps. It creates a padded png image to exactly match the size dividable by the stride and tile size.   \n",
    "Caution that you need to define the config file called \"config_train_Drive_UN\" as instructed to make sure it matches your paths and runns everything smoothly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing gdal work...\n",
      "Done with gdal work for 20241103_mimal_test.tif\n",
      "New Width:  14976 New Height:  12064\n",
      "Processed 1/1 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import counting_boats.train\n",
    "\n",
    "#Run preparation of the tif files into png and renamed the tif. \n",
    "counting_boats.train.prepare(\"config_train_Drive.yaml\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the png is created, as we are in the training of the model phase, we need to label the training image. In order to do so, you need to use LabelMe.  \n",
    "LabelMe is called in your terminal, manually typing \"labelme\".   \n",
    "You have to then annotate the waterholes on your padded png image. This creates at the end a json file with all my bounding boxes definitions. Those labels will be needed now to segment the image and the corresponding labels for training purposes. \n",
    "\n",
    "Once the whole manual annotation is done, save the outputs, and come back to this script to run the segmentation of the padded png image you just labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yolo_dir': 'C:/Users/fossatia/Documents/Waterholes_project/yolov5', 'python': 'python', 'raw_images': 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\extra_tif', 'proj_root': '.', 'output_dir': 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs', 'segmented_images': 'results\\\\images\\\\train', 'segmented_labels': 'results\\\\labels\\\\train', 'weights': './data/NN_weights.pt', 'cache': False, 'workers': 6, 'BATCH_SIZE': 8, 'EPOCHS': 500, 'img_size': 416, 'img_stride': 104, 'TILE_SIZE': 416, 'STRIDE': 104, 'path': '.', 'pngs': '.\\\\images\\\\pngs', 'labels': '.\\\\training\\\\labels', 'classifications': '.\\\\images\\\\classifications', 'training_path': '.\\\\training', 'train': '.\\\\training\\\\images', 'val': None, 'names': {0: 'Dry_WH', 1: 'WH_swamp', 2: 'WH_wet', 3: 'WH_sink', 4: 'U'}}\n",
      "['D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20230428_example.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20240101_mimal_test.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20240204_mimal_test.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20240324_mimal_test.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20240415_mimal_test.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20241103_mimal_test.json', 'D:\\\\Waterholes_project\\\\counting_waterholes\\\\training_v4\\\\pngs\\\\20250205_NT.json']\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20230428_example.png\n",
      "[6656 9984    3]\n",
      "We will have:  5673  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 5673/5673 [00:30<00:00, 187.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 4259 images\n",
      "Empty 4060 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20240101_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [01:17<00:00, 204.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13135 images\n",
      "Empty 13857 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20240204_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [01:19<00:00, 199.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 12975 images\n",
      "Empty 13539 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20240324_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [01:22<00:00, 194.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13081 images\n",
      "Empty 12665 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20240415_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [01:21<00:00, 196.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13005 images\n",
      "Empty 13594 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20241103_mimal_test.png\n",
      "[12064 14976     3]\n",
      "We will have:  15933  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 15933/15933 [01:22<00:00, 192.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 13064 images\n",
      "Empty 13825 images\n",
      "Cropping Image: D:\\Waterholes_project\\counting_waterholes\\training_v4\\pngs\\20250205_NT.png\n",
      "[ 8736 12064     3]\n",
      "We will have:  9153  images maximum\n",
      "90.0% of images without labels will be removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Segments: 100%|██████████| 9153/9153 [00:47<00:00, 193.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 8026 images\n",
      "Empty 5759 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import counting_boats.train\n",
    "\n",
    "#segment the png images\n",
    "counting_boats.train.segment(\"config_train_Drive.yaml\", train_val_split=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After segmentation, we evaluate the results of the segmentation and production of material to train the model using the \"train.describe\" function. \n",
    "Run the bellow cell to describe from created paths of segmented images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\images\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcounting_boats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#describe the created segmented images: \u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mcounting_boats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_train_Drive.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fossatia\\Documents\\Waterholes_project\\counting_waterholes\\counting_boats\\train.py:216\u001b[0m, in \u001b[0;36mdescribe\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    213\u001b[0m lab_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(labdir, lab)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Check if file is empty first (file size = 0)\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlab_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    217\u001b[0m     num_tiles_no_labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fossatia\\AppData\\Local\\miniconda3\\envs\\Boats\\lib\\genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsize\u001b[39m(filename):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import counting_boats.train\n",
    "\n",
    "#describe the created segmented images: \n",
    "counting_boats.train.describe(\"config_train_Drive.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the cull command which will remove images with no labels until 10% of the training set has no labels. This has to be done post segmentation as we don't know prior the the amount (depends on the segmentation). \n",
    "Using my created function as the official cull from Charlie doesn't work well. Mine runs all good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing label files in: D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\labels\\train\n",
      "Looking for corresponding images in: D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\images\\train\n",
      "Total label files found: 13565\n",
      "Empty label files found: 6063\n",
      "Non-empty label files: 7502\n",
      "Moving 5230 empty label files to maintain 10% ratio\n",
      "\n",
      "--- SUMMARY ---\n",
      "Total label files moved: 5230\n",
      "Total image files moved: 5230\n",
      "Remaining total label files: 8335\n",
      "Remaining empty label files: 833\n",
      "Empty labels now make up 9.99% of the dataset\n",
      "Empty labels moved to: D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\labels\\moved_empty_labels\n",
      "Corresponding images moved to: D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\images\\moved_empty_images\n",
      "\n",
      "SUCCESS: Empty labels now make up 10% or less of the dataset.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path \n",
    "import counting_boats.train\n",
    "\n",
    "#describe the created segmented images: \n",
    "counting_boats.train.cull_AF(\"config_train_Drive.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cull function is applied reducing the no instance images amount to 10%, we can try to train the model. \n",
    "But first let's reorganise the folders to be used in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\images\\val to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\val\\images\n",
      "Successfully copied to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\val\\images\n",
      "Copying from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\images\\train to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\train\\images\n",
      "Successfully copied to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\train\\images\n",
      "Copying from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\labels\\val to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\val\\labels\n",
      "Successfully copied to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\val\\labels\n",
      "Copying from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output\\labels\\train to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\train\\labels\n",
      "Successfully copied to D:\\Waterholes_project\\counting_waterholes\\training_v4\\train\\train\\labels\n",
      "\n",
      "----- REORGANIZATION SUMMARY -----\n",
      "Successful operations: 4\n",
      "Failed operations: 0\n",
      "\n",
      "All folders were successfully reorganized!\n",
      "\n",
      "New structure:\n",
      "- D:\\Waterholes_project\\counting_waterholes\\training_v4\\train/val/images (copied from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output/images/val)\n",
      "- D:\\Waterholes_project\\counting_waterholes\\training_v4\\train/val/labels (copied from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output/labels/val)\n",
      "- D:\\Waterholes_project\\counting_waterholes\\training_v4\\train/train/images (copied from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output/images/train)\n",
      "- D:\\Waterholes_project\\counting_waterholes\\training_v4\\train/train/labels (copied from D:\\Waterholes_project\\counting_waterholes\\training_v4\\output/labels/train)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import counting_boats.train\n",
    "\n",
    "counting_boats.train.reorganize_folders(\"config_train_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifiy now in the config file of the yolo model training the path directory of the run. then run the following code and go in the yolov5 folder to run it and train the model. \n",
    "\n",
    "This code provides you with the command to excecute in the cmd of the yolo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mpython C:/Users/fossatia/Documents/Waterholes_project/yolov5/train.py --device cuda:0 --img 416 --batch 8 --workers 6 --epochs 100 --data config_train_Drive.yaml --weights C:/Users/fossatia/Documents/Waterholes_project/yolov5/runs/train/exp3/weights/best.pt --save-period 50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import counting_boats.train\n",
    "\n",
    "#describe the created segmented images: \n",
    "counting_boats.train.train(\"config_train_Drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model when ordered directly into the cmd panel and not via notebook: \n",
    "Need to figure out how to do it from here to streamline the whole process though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --workers 2 --img 416 --batch 8 --epochs 150 --data config_train_GPU_yolo.yaml --weights yolov5s.pt --cache disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it actually seems that it runs automatically with the function train but we do not see any progression... \n",
    "Prefer for now to run it manually in the cmd of the yolov5 folder.  \n",
    "\n",
    "Changed the cache to the SSD drive we are using as we are limited in the storage available locally. \n",
    "Needed to set the project to the SSD which saves the outputs and doesn't increase the C: storage usage. \n",
    "\n",
    "Need to actually create the D:/temp and D:/yolo_run on your Drive or external directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set TMPDIR=D:/temp\n",
    "set TEMP=D:/temp\n",
    "set TMP=D:/temp\n",
    "set KMP_DUPLICATE_LIB_OK=TRUE \n",
    "python C:/Users/fossatia/Documents/Waterholes_project/yolov5/train.py --device cuda:0 --img 416 --batch 4 --workers 2 --epochs 50 --data C:\\Users\\fossatia\\Documents\\Waterholes_project\\counting_waterholes\\config_train_Drive.yaml --weights C:/Users/fossatia/Documents/Waterholes_project/yolov5/runs/train/exp3/weights/best.pt --cache False --project D:/yolo_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set KMP_DUPLICATE_LIB_OK=TRUE is not recommended on the error command... I tried to google it and it seems we should force an install of the Nomkl using 'conda install nomkl --channel conda-forge'. \n",
    "However, by doing so, dependencies might be altered. To be checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of this script. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Boats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
