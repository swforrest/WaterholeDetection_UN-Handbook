#-------------------
#All absolute paths you need to change are located at the top of this file
#All the other ones should be relative paths and thus do not need to be created in your folder. 


#-------------------
##Expected folder structure##
#They should be created as you go along the functions but as a reference this is how it will look like at the end:

#testing\  
#   classifications\                   # Classifications (segmented labels from model detection)
#       date(s)\
#           image_name\
#   labels\                            # Segmented labels output path
#       date(s)\
#           image_name\
#   plots\                             #plots outputs from testing 
#   pngs\                              # pngs created, json labels, and location of the created labelme_auto.json files. 
#   raw_images\                        # tif files location
#   segmented_images\                  # segmented images output 


#-------------------
##General paths## 

#MODIFY ALL THOSE PATHS TO YOUR ABSOLUTE PATHS:

#Yolo directory:
yolo_dir: C:\Users\adria\OneDrive - AdrianoFossati\Documents\MASTER Australia\RA\Waterholes_project\yolov5
# Configuration for Validation/Analysis Runs.
path:  C:\Users\adria\OneDrive - AdrianoFossati\Documents\MASTER Australia\RA\Waterholes_project\WaterholeDetection_UN-Handbook\testing
# Validation run with Best weights from your last model training (in my case named "exp_v4") or the weights of your choice.
weights: D:\yolo_runs\exp_v4\weights\best.pt
#To use the GPU, use the cuda:0. Might need some updating of your dependencies to match your GPU version.
device: cuda:0
#Repository root path (where this file is)
proj_root: C:\Users\adria\OneDrive - AdrianoFossati\Documents\MASTER Australia\RA\Waterholes_project\WaterholeDetection_UN-Handbook 



#-------------------
##Those paths are relative and should not need to be modified.##

#Python language. Shouldn't need any change. 
python: python
# pngs created, json labels, and location of the created labelme_auto.json files. 
pngs: ./pngs  
#tif files location:
raw_images: ./raw_images
# Segmented images output path
segmented_images: ./segmented_images 
#Segmented labels output path
labels: ./labels 
# Classifications (segmented labels from model detection) 
#{Caution! need to delete this path every time you run the detection, if you run into errors etc...}
classifications: ./classifications 
#figures and plots outputs 
plots: ./plots 
#not actually used in the testing 
output_dir: ./results 


#-------------
##WH clustering, testing, and plotting parameters##

#plotting WH size of boxes when comparing visually the labeled vs classified WH. To be fine tuned as pleased. 
plot_box_size: 100 

use_comet: False # If true, make sure comet is setup (needs env vars or a .comet.config file)

#Various values and parameters of the model manipulation. 
#To be checked. Adapted when running it. 
workers: 6
BATCH_SIZE: 8
EPOCHS: 250
img_size: 416
img_stride: 104
TILE_SIZE: 416
STRIDE: 104

#Testing configs. Added precision on the cutoff pixel stats:
CONFIDENCE_THRESHOLD: 0.7

#free to decide to change and play around with those values to cluster the detections together better. 
STAT_DISTANCE_CUTOFF_PIX_DRY: 120
STAT_DISTANCE_CUTOFF_PIX_WET: 120
STAT_DISTANCE_CUTOFF_PIX_SWAMP: 170
STAT_DISTANCE_CUTOFF_PIX_SINK: 120
STAT_DISTANCE_CUTOFF_PIX_U: 120

# The lat/long cutoff should be roughly related to the resolution of the images
# For 3m resolution, 10 pix is roughly 30m. At approx -27 deg lat, this is approx 0.0003 degrees.
STAT_DISTANCE_CUTOFF_LATLONG: 0.00025 

#Comparison of my labels and the clustered ones of the classification:
COMPARE_DISTANCE_CUTOFF_PIX: 40


#------------------
##Tasks to be performed if running by modules.## 

#I'm just putting all false and run manually in our pipeline. Not ran by modules so not necessary.
tasks:
  # These 4 are not required if have been done before (and above paths are absolute and exist)
  prepare: False # Prepare for labelling
  segment: False # Segment images/labels
  run_detection: False # Run the classifier
  backwards_annotation: False # Generate annotations from the classifier output

  analyse:
    # Main analysis step: cluster and compare outputs a comparison csv
    compare_detections_to_ground_truth: False # Cluster and compare results to ground truth (have to do this for all analysis below)

    # Supplementary analysis
    plots:
      confusion_matrix: False # Confusion matrix
      boat_count_compare: False # Compare boat counts in each image detections to ground truth and output a graph
    images:
      all_mistakes: False # Collate all mistakes into images with comparison
      subimage_confidence: False # Show confidence of detection for all subimages of a given boat (number of random boats to do this for)
      coverage_heatmap: False # generate a tif file with a heatmap of coverage of images in the test data
